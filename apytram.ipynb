{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tempfile\n",
    "import shutil\n",
    "import logging\n",
    "import argparse\n",
    "import subprocess\n",
    "\n",
    "from lib import ApytramNeeds\n",
    "from lib import BlastPlus\n",
    "from lib import Trinity\n",
    "from lib import Aligner\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "### Option defining\n",
    "parser = argparse.ArgumentParser(prog = \"apytram.py\",\n",
    "                                 description='''\n",
    "    Run apytram.py on a fastq file to retrieve\n",
    "    homologous sequences of bait sequences.''')\n",
    "\n",
    "requiredOptions = parser.add_argument_group('required arguments')\n",
    "requiredOptions.add_argument('-d', '--database', nargs='?', type=str,\n",
    "                             help='Database preffix name', required=True)\n",
    "requiredOptions.add_argument('-t', '--database_type', type=str, choices=[\"single\",\"paired\"],\n",
    "                             help='single or paired end database', required=True)\n",
    "\n",
    "parser.add_argument('--version', action='version', version='%(prog)s 1.0')\n",
    "parser.add_argument('-log', nargs='?', type=str, default=\"apytram.log\",\n",
    "                   help = \"a log file to report avancement (default: apytram.log)\"\n",
    "                   )\n",
    "parser.add_argument('--threads',  type=int,\n",
    "                    help = \"Available threads. (Default 1)\",\n",
    "                    default = 1 )\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('-fa', '--fasta',  type=str,\n",
    "                   help = \"Fasta formatted RNA-seq data to build the database of reads\")\n",
    "parser.add_argument('-fq', '--fastq',  type=str,\n",
    "                   help = \"Fastq formatted RNA-seq data to build the database of reads\")\n",
    "parser.add_argument('-out', '--output_preffix',  type=str, default = \"./apytram\",\n",
    "                   help = \"Output preffix (Default ./apytram)\")\n",
    "\n",
    "parser.add_argument('-tmp',  type=str,\n",
    "                    help = \"Directory to stock all intermediary files for the apytram run. (default: a directory in /tmp which will be removed at the end)\",\n",
    "                    default = \"\" )\n",
    "parser.add_argument('--keep_iterations',  action='store_true',\n",
    "                    help = \"A fasta file will be created at each iteration.\"\n",
    "                   )\n",
    "\n",
    "parser.add_argument('-q', '--query',  type=str,\n",
    "                    help = \"Fasta file (nt) with bait sequence for the apytram run.\" )\n",
    "parser.add_argument('-i', '--iteration_max',  type=int,\n",
    "                    help = \"Maximum number of iteration. (Default 5)\",\n",
    "                    default = 5 )\n",
    "parser.add_argument('-e', '--evalue',  type=float,\n",
    "                    help = \"Evalue. (Default 1e-3)\",\n",
    "                    default = 1e-3 )\n",
    "parser.add_argument('--required_coverage',  type=float,\n",
    "                    help = \"Required coverage of a bait sequence to stop iteration (Default: No threshold)\",\n",
    "                    default = 200 )\n",
    "\n",
    "parser.add_argument('-id', '--min_id',  type=int,\n",
    "                    help = \"Minimum identity percentage with a query to keep a sequence  (Default 50)\",\n",
    "                    default = 50 )\n",
    "parser.add_argument('-l', '--min_len',  type=int,\n",
    "                    help = \"Minimum length to keep a sequence  (Default 200)\",\n",
    "                    default = 200 )\n",
    "\n",
    "StatOptions = parser.add_argument_group('Arguments for statistics and plots')\n",
    "StatOptions.add_argument('--stats', action='store_true',\n",
    "                             help='Create files with statistics on each iteration')\n",
    "StatOptions.add_argument('--plot', action='store_true',\n",
    "                             help='Create file with plot on statistics on each iteration')\n",
    "\n",
    "\n",
    "\n",
    "### Option parsing\n",
    "args = parser.parse_args()\n",
    "\n",
    "### Arguments reading\n",
    "MaxIteration = args.iteration_max\n",
    "Threads = args.threads\n",
    "Evalue = args.evalue\n",
    "MinIdentityPercentage = args.min_id\n",
    "MinLength = args.min_len\n",
    "KeepIterations = args.keep_iterations\n",
    "RequiredCoverage = args.required_coverage\n",
    "\n",
    "if args.database_type == \"paired\":\n",
    "    PairedData = True\n",
    "else:\n",
    "    PairedData = False\n",
    "\n",
    "if args.plot:\n",
    "    args.stats = True\n",
    "\n",
    "### Set up the output directory\n",
    "if args.log:\n",
    "    LogDirName = os.path.dirname(args.log)\n",
    "    if not os.path.isdir(LogDirName) and LogDirName:\n",
    "        os.makedirs(LogDirName)\n",
    "\n",
    "### Set up the logger\n",
    "LogFile = args.log\n",
    "# create logger with 'spam_application'\n",
    "logger = logging.getLogger('apytram')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler(LogFile)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.ERROR)\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "ch.setFormatter(formatter)\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "### Set up the working directory\n",
    "if args.tmp:\n",
    "    if os.path.isdir(args.tmp):\n",
    "        logger.info(\"The temporary directory %s exists\" %(args.tmp) )\n",
    "    else:\n",
    "        logger.info(\"The temporary directory %s does not exist, it will be created\" % (args.tmp))\n",
    "        os.makedirs(args.tmp)\n",
    "    TmpDirName = args.tmp\n",
    "else:\n",
    "    TmpDirName = tempfile.mkdtemp(prefix='tmp_apytram')\n",
    "\n",
    "### Set up the output directory\n",
    "if args.output_preffix:\n",
    "    OutDirName = os.path.dirname(args.output_preffix)\n",
    "    OutPreffixName = args.output_preffix\n",
    "    if os.path.isdir(OutDirName):\n",
    "        logger.info(\"The output directory %s exists\" %(os.path.dirname(args.output_preffix)) )\n",
    "    elif OutDirName: # if OutDirName is not a empty string we create the directory\n",
    "        logger.info(\"The temporary directory %s does not exist, it will be created\" % (os.path.dirname(args.output_preffix)))\n",
    "        os.makedirs(os.path.dirname(args.output_preffix))\n",
    "else:\n",
    "    logger.error(\"The output preffix must be defined\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "### Check that there is a database else built it\n",
    "DatabaseName = args.database\n",
    "CheckDatabase_BlastdbcmdProcess = BlastPlus.Blastdbcmd(DatabaseName, \"\", \"\")\n",
    "if not CheckDatabase_BlastdbcmdProcess.is_database():\n",
    "    logger.info(\"Database %s does not exist\" % DatabaseName)\n",
    "    #Build blast formated database from a fasta file\n",
    "    if args.fastq or args.fasta:\n",
    "        if args.fastq:\n",
    "            if not os.path.isfile(args.fastq):\n",
    "                logger.error(\"The fastq file (-fq) does not exist.\")\n",
    "                sys.exit(1)\n",
    "            else:\n",
    "                # Format the fastq file in fasta\n",
    "                InputFasta = TmpDirName + \"/\" + os.path.basename(args.fastq) + \".fasta\"\n",
    "                ExitCode = ApytramNeeds.fastq2fasta(args.fastq,InputFasta)\n",
    "        elif args.fasta:\n",
    "            InputFasta = args.fasta\n",
    "            \n",
    "        if not os.path.isfile(InputFasta):\n",
    "            logger.error(\"The fasta file (-fa) does not exist.\")\n",
    "            sys.exit(1)\n",
    "        if os.path.isdir(os.path.dirname(DatabaseName)):\n",
    "            logger.info(\"Database directory exists\")\n",
    "        else:\n",
    "            logger.info(\"Database directory does not exist, we create it\")\n",
    "            os.makedirs(os.path.dirname(DatabaseName))\n",
    "        # database building\n",
    "        logger.info(DatabaseName + \" database building\")\n",
    "        MakeblastdbProcess = BlastPlus.Makeblastdb(InputFasta,DatabaseName)\n",
    "        ExitCode = MakeblastdbProcess.launch()\n",
    "    else :\n",
    "        logger.error(\"The database is not formatted ! A fasta file (-fa) or a fastq file (-fq) is required !\")\n",
    "        sys.exit(1)\n",
    "\n",
    "CheckDatabase_BlastdbcmdProcess = BlastPlus.Blastdbcmd(DatabaseName, \"\", \"\")\n",
    "if not CheckDatabase_BlastdbcmdProcess.is_database():\n",
    "    logger.error(\"Problem in the database building\")\n",
    "    logger.info(\"Database %s does not exist\" % DatabaseName)\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    logger.info(\"Database %s exists\" % DatabaseName)\n",
    "\n",
    "### If there is a query continue, else stop\n",
    "if not args.query:\n",
    "    logger.info(\"There is no query (-q), apytram have finished.\")\n",
    "    quit()\n",
    "elif not os.path.isfile(args.query):\n",
    "    logger.error(args.query+\" (-q) is not a file.\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    QueryFile = args.query\n",
    "    logger.info(\"DB: \\\"%s\\\"\\tQuery: \\\"%s\\\"\" %(DatabaseName,QueryFile))\n",
    "    \n",
    "    \n",
    "\n",
    "### Make iterations\n",
    "# Initialisation\n",
    "i = 0\n",
    "Stop = False\n",
    "BaitSequences = QueryFile\n",
    "IterationNotFinished = False\n",
    "\n",
    "StatsDict = {\"iter_0\":{\"IterationTime\": 0,\n",
    "                \"CumulTime\": time.time() - start_time,\n",
    "                \"LargeCoverage\": 0,\n",
    "                \"StrictCoverage\": 0,\n",
    "                \"NbContigs\": 0,\n",
    "                \"AverageLength\": 0,\n",
    "                \"TotalLength\": 0,\n",
    "                \"BestLength\":0,\n",
    "                \"AverageScore\": 0,\n",
    "                \"TotalScore\": 0,\n",
    "                \"BestScore\":0,\n",
    "                \"AverageIdentity\": 0,\n",
    "                \"TotalIdentity\": 0,\n",
    "                \"BestIdentity\":0,\n",
    "                \"BlastTime\": 0,\n",
    "                \"TrinityTime\": 0,\n",
    "                \"Exonerate1Time\":0,\n",
    "                \"Exonerate2Time\":0,\n",
    "                \"MafftTime\":0,\n",
    "                \"PythonTime\":0\n",
    "                }}\n",
    "    \n",
    "logger.info(\"Iterations begin\")\n",
    "start_iter = time.time()\n",
    "while (i < MaxIteration) and (Stop == False):\n",
    "    start_iter_i = time.time()\n",
    "    i+=1\n",
    "    StatsDict[\"iter_%d\" %(i)] = StatsDict[\"iter_%d\" %(i-1)].copy()\n",
    "    StatsDict[\"iter_%d\" %(i)].update({\"IterationTime\": 0,\n",
    "                \"CumulTime\": 0,\n",
    "                \"BlastTime\": 0,\n",
    "                \"TrinityTime\": 0,\n",
    "                \"Exonerate1Time\":0,\n",
    "                \"Exonerate2Time\":0,\n",
    "                \"PythonTime\":0\n",
    "                })\n",
    "    \n",
    "    logger.info(\"Iteration %d/%d\" %(i,MaxIteration))\n",
    "    \n",
    "    ### Blast bait sequences on database of reads\n",
    "    \n",
    "    logger.info(\"Blast bait sequences on reads database\")\n",
    "    start_blast_time = time.time()\n",
    "    ReadNamesFile = \"%s/ReadNames.%d.txt\" % (TmpDirName,i)\n",
    "    BlastnProcess = BlastPlus.Blast(\"blastn\", DatabaseName, BaitSequences)\n",
    "    BlastnProcess.Evalue = Evalue\n",
    "    BlastnProcess.Task = \"blastn\"\n",
    "    BlastnProcess.Threads = Threads\n",
    "    BlastnProcess.OutFormat = \"6 sacc\"\n",
    "    # Write read names in ReadNamesFile\n",
    "    ExitCode = BlastnProcess.launch(ReadNamesFile)\n",
    "    StatsDict[\"iter_%d\" %(i)][\"BlastTime\"] = time.time() - start_blast_time\n",
    "    logger.debug(\"blast --- %s seconds ---\" % (StatsDict[\"iter_%d\" %(i)][\"BlastTime\"]))\n",
    "    if PairedData:\n",
    "        # Get paired reads names\n",
    "        ExitCode = ApytramNeeds.add_paired_read_names(ReadNamesFile)\n",
    "        \n",
    "    # Compare the read list names with the list of the previous iteration:\n",
    "    Identical = ApytramNeeds.are_identical(ReadNamesFile,\"%s/ReadNames.%d.txt\" % (TmpDirName,i-1))\n",
    "    if Identical:\n",
    "        logger.info(\"Reads from the current iteration are identical than the previous\")\n",
    "        Stop = True\n",
    "        IterationNotFinished = True\n",
    "        i -= 1\n",
    "    else:\n",
    "        \n",
    "        ### Retrieve sequences\n",
    "        \n",
    "        logger.info(\"Retrieve sequences\")\n",
    "        ReadFasta = TmpDirName + \"/Reads.%d.fasta\" % (i)\n",
    "        BlastdbcmdProcess = BlastPlus.Blastdbcmd(DatabaseName, ReadNamesFile, ReadFasta)\n",
    "        BlastdbcmdProcess.launch()\n",
    "        \n",
    "        ### Launch Trinity\n",
    "        \n",
    "        start_trinity_time = time.time()\n",
    "        logger.info(\"Launch Trinity\")\n",
    "        TrinityFasta = \"%s/Trinity_iter_%d\" %(TmpDirName, i)\n",
    "        TrinityProcess = Trinity.Trinity(ReadFasta,TrinityFasta)\n",
    "        TrinityProcess.CPU = Threads\n",
    "        # Keep only contig with a length superior to MinLength\n",
    "        TrinityProcess.MinLength = MinLength\n",
    "        if PairedData:\n",
    "            TrinityProcess.Paired = True\n",
    "        # Use the  --full_cleanup Trinity option to keep only the contig file\n",
    "        ExitCode = 0\n",
    "        TrinityProcess.FullCleanup = True\n",
    "        ExitCode = TrinityProcess.launch()\n",
    "        TrinityFasta = TrinityFasta + \".Trinity.fasta\"\n",
    "        StatsDict[\"iter_%d\" %(i)][\"TrinityTime\"] = time.time() - start_trinity_time\n",
    "        logger.debug(\"trinity --- %s seconds ---\" %(StatsDict[\"iter_%d\" %(i)][\"TrinityTime\"]))\n",
    "        if ExitCode != 0: # Trinity found nothing\n",
    "            logger.error(\"Trinity found nothing (ExitCode: %d)\" %ExitCode)\n",
    "            Stop = True\n",
    "            IterationNotFinished = True\n",
    "            i -=1\n",
    "        else:\n",
    "            \n",
    "            ### Filter Trinity contigs to keep only homologous sequences of the reference genes\n",
    "            \n",
    "            logger.info(\"Compare Trinity results with query sequences\")\n",
    "            # We use Exonerate \n",
    "            TrinityExonerate = \"%s/Trinity_iter_%d.exonerate\" % (TmpDirName, i)\n",
    "            start_exo_time = time.time()\n",
    "            TrinityExonerateProcess = Aligner.Exonerate(QueryFile,TrinityFasta)\n",
    "            # We want to keep only the best hit for each Trinity sequences\n",
    "            TrinityExonerateProcess.Bestn = 1\n",
    "            TrinityExonerateProcess.Model = \"cdna2genome\"\n",
    "            # We customize our output format\n",
    "            TrinityExonerateProcess.Ryo = \"%ti\\t%qi\\t%ql\\t%tal\\t%tl\\t%tab\\t%tae\\t%s\\t%pi\\t%qab\\t%qae\\n\"\n",
    "            TrinityExonerateResult = TrinityExonerateProcess.get_output()\n",
    "            # We write the result in a file\n",
    "            TrinityExonerateFile = open(TrinityExonerate,\"w\")\n",
    "            TrinityExonerateFile.write(TrinityExonerateResult)\n",
    "            TrinityExonerateFile.close()\n",
    "            # Keep only sequence with a identity percentage > MinIdentitypercentage on the whole hit\n",
    "            BestScoreNames, TrinityExonerateResultsDict, StatsIter = ApytramNeeds.parse_exonerate_results(TrinityExonerateResult, MinIdentityPercentage)\n",
    "            StatsDict[\"iter_%d\" %(i)].update(StatsIter)\n",
    "            FilteredSequenceNames = TrinityExonerateResultsDict.keys()\n",
    "            StatsDict[\"iter_%d\" %(i)][\"Exonerate1Time\"] = time.time() - start_exo_time\n",
    "            logger.debug(\"exonerate on trinity --- %s seconds ---\" % (StatsDict[\"iter_%d\" %(i)][\"Exonerate1Time\"]))\n",
    "            \n",
    "            # Filter hit\n",
    "            logger.info(\"Filter sequence with a identity percentage superior to %d\" %(MinIdentityPercentage)) \n",
    "            FileteredTrinityFasta =  \"%s/Trinity_iter_%d.filtered.fasta\" % (TmpDirName, i)\n",
    "            ExitCode = ApytramNeeds.filter_fasta(TrinityFasta, FilteredSequenceNames, FileteredTrinityFasta)\n",
    "            \n",
    "            ### Validated sequences become bait sequences\n",
    "            \n",
    "            BaitSequences = FileteredTrinityFasta\n",
    "\n",
    "            ### Compare to the previous iteration\n",
    "            \n",
    "            logger.info(\"Compare results with the previous iteration\")\n",
    "            \n",
    "            #Check if the number of contigs has changed\n",
    "            \n",
    "            logger.info(\"Check if the number of contigs has changed\")\n",
    "            StatsDict[\"iter_%d\" %(i)][\"NbContigs\"] = len(FilteredSequenceNames)\n",
    "            \n",
    "            if StatsDict[\"iter_%d\" %(i)][\"NbContigs\"] != StatsDict[\"iter_%d\" %(i-1)][\"NbContigs\"]:\n",
    "                 logger.info(\"The number of contigs has changed\")          \n",
    "            elif i >= 2:\n",
    "                logger.info(\"Refind the \\\"brother\\\" contig from the previous contig for each contig and check they are different\")\n",
    "                # We use Exonerate \n",
    "                start_exo_time = time.time()\n",
    "                ExonerateProcess = Aligner.Exonerate(FileteredTrinityFasta, \"%s/Trinity_iter_%d.filtered.fasta\" % (TmpDirName,i-1) )\n",
    "                # We want to keep only the best hit for each contigs\n",
    "                ExonerateProcess.Bestn = 1\n",
    "                ExonerateProcess.Model = \"est2genome\"\n",
    "                # We customize our output format\n",
    "                ExonerateProcess.Ryo = \"%ti\\t%qi\\t%ql\\t%qal\\t%tal\\t%tl\\t%pi\\n\"\n",
    "                ExonerateResult = ExonerateProcess.get_output()\n",
    "                AlmostIdenticalResults = ApytramNeeds.check_almost_identical_exonerate_results(ExonerateResult)\n",
    "                if AlmostIdenticalResults:\n",
    "                    logger.info(\"Contigs are almost identical than the previous iteration (Same size (~98%), > 99% identity)\")\n",
    "                    Stop =True\n",
    "                StatsDict[\"iter_%d\" %(i)][\"Exonerate2Time\"] = time.time() - start_exo_time\n",
    "                logger.debug(\"exonerate on previous iter --- %s seconds ---\" % (StatsDict[\"iter_%d\" %(i)][\"Exonerate2Time\"]))\n",
    "     \n",
    "            # Check that the coverage has inscreased compared to the previous iteration\n",
    "        \n",
    "            logger.info(\"Check that the coverage has inscreased compared to the previous iteration\")\n",
    "            # We use Mafft\n",
    "            start_mafft_time = time.time()\n",
    "            MafftProcess = Aligner.Mafft(QueryFile)\n",
    "            MafftProcess.QuietOption = True\n",
    "            MafftProcess.AdjustdirectionOption = True\n",
    "            MafftProcess.AddOption = FileteredTrinityFasta\n",
    "            MafftResult = MafftProcess.get_output()\n",
    "            StatsDict[\"iter_%d\" %(i)][\"StrictCoverage\"], StatsDict[\"iter_%d\" %(i)][\"LargeCoverage\"] = ApytramNeeds.calculate_coverage(MafftResult)\n",
    "            logger.info(\"Strict Coverage: %d\\tLarge Coverage: %d\" %(StatsDict[\"iter_%d\" %(i)][\"StrictCoverage\"], StatsDict[\"iter_%d\" %(i)][\"LargeCoverage\"]))\n",
    "            StatsDict[\"iter_%d\" %(i)][\"MafftTime\"] = time.time() - start_mafft_time\n",
    "            logger.debug(\"mafft --- %s seconds ---\" % (StatsDict[\"iter_%d\" %(i)][\"MafftTime\"]))\n",
    "            \n",
    "            # Stop iteration if the Largecoverage is not improved and also the Total length\n",
    "            \n",
    "            if StatsDict[\"iter_%d\" %(i)][\"TotalLength\"] > StatsDict[\"iter_%d\" %(i-1)][\"TotalLength\"]:\n",
    "                pass\n",
    "            elif StatsDict[\"iter_%d\" %(i)][\"TotalScore\"] > StatsDict[\"iter_%d\" %(i-1)][\"TotalScore\"]:\n",
    "                pass\n",
    "            elif StatsDict[\"iter_%d\" %(i)][\"LargeCoverage\"] <= StatsDict[\"iter_%d\" %(i-1)][\"LargeCoverage\"]:\n",
    "                logger.info(\"This iteration have a large coverage inferior (or equal) to the previous iteration\")\n",
    "                Stop = True\n",
    "            \n",
    "            # Stop iteration if the RequiredCoverage is attained\n",
    "            if StatsDict[\"iter_%d\" %(i)][\"LargeCoverage\"] >= RequiredCoverage:\n",
    "                logger.info(\"This iteration attains the required bait sequence coverage (%d >= %d)\" % (StrictCoverage,RequiredCoverage))\n",
    "                Stop = True\n",
    "\n",
    "            ### Write a fasta file for this iteration if tere is the option --keep_iterations\n",
    "            \n",
    "            if KeepIterations:\n",
    "                # Best sequences of the iteration\n",
    "                ExitCode = ApytramNeeds.write_apytram_output(FileteredTrinityFasta, TrinityExonerateResultsDict,\n",
    "                                                 \"%s.iter_%d.best.fasta\" %(OutPreffixName,i), \n",
    "                                                 Header = TrinityExonerateProcess.Ryo.replace('%',\"\").replace(\"\\n\",\"\").split(),\n",
    "                                                 Names = BestScoreNames,\n",
    "                                                 Message = \"iter_%d.\" %i)\n",
    "                # All sequences of the iteration\n",
    "                ExitCode = ApytramNeeds.write_apytram_output(FileteredTrinityFasta,\n",
    "                                                 TrinityExonerateResultsDict,\n",
    "                                                 \"%s.iter_%d.fasta\" %(OutPreffixName,i),\n",
    "                                                 Header = TrinityExonerateProcess.Ryo.replace('%',\"\").replace(\"\\n\",\"\").split(),\n",
    "                                                 Message = \"iter_%d.\" %i)\n",
    "\n",
    "    if IterationNotFinished:\n",
    "            Reali = i + 1\n",
    "    else: \n",
    "        Reali = i\n",
    "    \n",
    "    NoPythonTime = StatsDict[\"iter_%d\" %(Reali)][\"BlastTime\"] + StatsDict[\"iter_%d\" %(Reali)][\"TrinityTime\"] +\\\n",
    "                 StatsDict[\"iter_%d\" %(Reali)][\"MafftTime\"] + StatsDict[\"iter_%d\" %(Reali)][\"Exonerate1Time\"] +\\\n",
    "                 StatsDict[\"iter_%d\" %(Reali)][\"Exonerate2Time\"]\n",
    "    StatsDict[\"iter_%d\" %(Reali)].update({\"IterationTime\": time.time() - start_iter_i,\n",
    "                                          \"CumulTime\": time.time() - start_iter,\n",
    "                                          \"PythonTime\": time.time() - start_iter_i - NoPythonTime })\n",
    "    \n",
    "    logger.debug(\"iteration %d --- %s seconds ---\" % (Reali, time.time() - start_iter_i))\n",
    "\n",
    "\n",
    "#### Write output\n",
    "\n",
    "\n",
    "logger.info(\"End of Iterations\")\n",
    "if i: #We check that there is at least one iteration with a result\n",
    "    logger.info(\"Write outputfiles\")\n",
    "    # Best sequences\n",
    "    ExitCode = ApytramNeeds.write_apytram_output(FileteredTrinityFasta, TrinityExonerateResultsDict,\n",
    "                                                 OutPreffixName+\".best.fasta\", \n",
    "                                                 Header = TrinityExonerateProcess.Ryo.replace('%',\"\").replace(\"\\n\",\"\").split(),\n",
    "                                                 Names = BestScoreNames)\n",
    "    # Last iteration\n",
    "    ExitCode = ApytramNeeds.write_apytram_output(FileteredTrinityFasta,\n",
    "                                                 TrinityExonerateResultsDict,\n",
    "                                                 OutPreffixName+\".fasta\",\n",
    "                                                 Header = TrinityExonerateProcess.Ryo.replace('%',\"\").replace(\"\\n\",\"\").split(),)\n",
    "    if args.stats:\n",
    "        logger.info(\"Write statistics file (OutPreffix.stats.csv)\")\n",
    "        ApytramNeeds.write_stats(StatsDict,OutPreffixName)\n",
    "        if args.plot:\n",
    "            logger.info(\"Create plot from the statistics file (OutPreffix.stats.pdf)\")\n",
    "            ApytramNeeds.create_plot(StatsDict,OutPreffixName)\n",
    "        \n",
    "else:\n",
    "    logger.warn(\"No results\")\n",
    "    \n",
    "### Remove tempdir if the option --tmp have not been use\n",
    "if not args.tmp:\n",
    "    logger.debug(\"Remove the temporary directory\")\n",
    "    #Remove the temporary directory :\n",
    "    if \"tmp_apytram\" in TmpDirName:\n",
    "        shutil.rmtree(TmpDirName)\n",
    "        \n",
    "logger.debug(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
